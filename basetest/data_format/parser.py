import pyarrow.ipc as ipc
import pyarrow as pa
import os

def analyze_arrow_file(filepath):
    print(f"ğŸ“‚ ë¶„ì„ íŒŒì¼ ê²½ë¡œ: {filepath}")

    with open(filepath, "rb") as f:
        reader = ipc.RecordBatchFileReader(f)

        # ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¶œë ¥
        schema = reader.schema
        print("\nğŸ“ Schema:")
        print(schema)

        # RecordBatch ìˆ˜
        num_batches = reader.num_record_batches
        print(f"\nğŸ§± RecordBatch ìˆ˜: {num_batches}")

        # ë°°ì¹˜ ì •ë³´ ì¶œë ¥
        total_rows = 0
        total_bytes = 0

        print("\nğŸ“¦ ê° RecordBatch ì •ë³´:")
        for i in range(num_batches):
            batch = reader.get_batch(i)
            rows = batch.num_rows
            size = batch.nbytes
            print(f"  - Batch {i}: {rows} rows, {size / 1024:.2f} KB")
            total_rows += rows
            total_bytes += size

        print(f"\nğŸ“ˆ ì „ì²´ row ìˆ˜: {total_rows}")
        print(f"ğŸ“ ì „ì²´ ë°ì´í„° í¬ê¸° (ì••ì¶• í•´ì œ ê¸°ì¤€): {total_bytes / (1024 * 1024):.2f} MB")

def print_block_offsets(filepath):
    with open(filepath, 'rb') as f:
        reader = ipc.RecordBatchFileReader(f)
        schema = reader.schema

        print("\nğŸ“ Schema:")
        print(schema)

        print(f"\nğŸ§± RecordBatch ìˆ˜: {reader.num_record_batches}")
        for i in range(reader.num_record_batches):
            batch = reader.get_batch(i)
            print(f"  - Batch {i}: rows={batch.num_rows}, size={batch.nbytes / 1024:.2f} KB")

        # ë‹¤ìŒ ì •ë³´ëŠ” ë‚´ë¶€ êµ¬ì¡°ì´ë©° ê³µì‹ APIë¡œëŠ” offsetì„ ì œê³µí•˜ì§€ ì•ŠìŒ

# ì‹¤í–‰
if __name__ == "__main__":
    filepath = os.path.expanduser("~/Desktop/tokenized_dataset/standard.arrow")
    analyze_arrow_file(filepath)
    print_block_offsets(filepath)
