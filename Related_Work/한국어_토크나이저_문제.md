1. 출처 논문
서울대학교 대학원
데이터사이언스학과
이 소 람
Analysis of Tokenizers for
Various Korean NLP Tasks

실험 결과
데이터셋
약 15.7GB의 한국어 데이터(Wikipedia, 나무위키 등)를 사용해 토크나이저 학습.
다운스트림 태스크: KLUE-NLI, KLUE-STS, NSMC.

성능 평가
F1-Score, Accuracy로 성능을 측정.
Mecab-WordPiece 조합이 KLUE-STS에서 최고 성능을 기록(F1-score: 0.7541).
NSMC(감정 분석)에서는 Mecab 단독 사용이 가장 높은 정확도를 기록(Accuracy: 86.8550).

한국어는 접사와 어미 등 문법적 요소가 어절에 포함되어 있어 추가적인 토큰화 과정이 필요하다.

토크나이저 성능 비교
BPE, Workpiece : 빈도 기반 병합 방식으로 어미나 조사 분리가 부족하여 문법적 처리 약함
Mecab : 형태소 단위 토크나이저로 문법적 요소를 잘 반영하여, 성능이 높다.

**조합(Mecab + Subword): 문법 요소와 서브워드 병합의 장점을 활용해 가장 우수한 성능을 보임.**
내 의견 : 그러나 2개를 조합하면 두 단계의 연산이 필요하다. 형태소 분석 후 서브워드 토큰화를 추가로 CPU 및 메모리 자원을 많이 소모하는데,
형태소 분석과 서브워드 병합 연산을 ISP 병렬 연산으로 나눠 수행

서브워드 토크나이저는 "데이터 이동 비용"이 크다.
긴 한국어 어절은 분리된 서브워드 토큰 수가 많아서, 토큰 간 이동 및 메모리 입출력 비용이 증가함.
어휘 크기가 크면 더 많은 어휘 데이터를 저장하고 검색해야함으로 이동비용이 더 많이 듦


**형태소 단위 토크나이저**
형태소(morpheme) 단위로 텍스트를 나누는 것이다. 한국어와 같은 교착어에서 중요함
의미를 가지는 최소 단위 분리 

**한국어 토크나이징의 어려움**

완성형 한글 인코딩으로 인해 "글자수"가 많음.
한글의 특성으로 서브워드 기반 기법들이 제성능을 내지 못한다.
